{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Edwin372/Thesis/blob/main/Vudenc.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6E4z66vGHOFS",
        "outputId": "0f8d695b-deba-431e-be98-463607ac55e6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cloning into 'VulnerabilityDetection'...\n",
            "remote: Enumerating objects: 1250, done.\u001b[K\n",
            "remote: Counting objects: 100% (158/158), done.\u001b[K\n",
            "remote: Compressing objects: 100% (133/133), done.\u001b[K\n",
            "remote: Total 1250 (delta 44), reused 133 (delta 25), pack-reused 1092\u001b[K\n",
            "Receiving objects: 100% (1250/1250), 294.55 MiB | 13.05 MiB/s, done.\n",
            "Resolving deltas: 100% (473/473), done.\n",
            "Checking out files: 100% (206/206), done.\n"
          ]
        }
      ],
      "source": [
        "!git clone https://github.com/LauraWartschinski/VulnerabilityDetection.git\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hmxR3QtnvJM8",
        "outputId": "15549c38-52eb-4fc2-c95a-4556bb708098"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-0.9.3-py3-none-any.whl (419 kB)\n",
            "\u001b[K     |████████████████████████████████| 419 kB 26.6 MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (21.3)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (4.1.1)\n",
            "Requirement already satisfied: numpy>=1.17.2 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.21.6)\n",
            "Requirement already satisfied: torch>=1.3.1 in /usr/local/lib/python3.7/dist-packages (from torchmetrics) (1.12.1+cu113)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.7/dist-packages (from packaging->torchmetrics) (3.0.9)\n",
            "Installing collected packages: torchmetrics\n",
            "Successfully installed torchmetrics-0.9.3\n"
          ]
        }
      ],
      "source": [
        "!pip install torchmetrics"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "E3_ZpOcI9sGS"
      },
      "outputs": [],
      "source": [
        "!mv /content/VulnerabilityDetection/Code/w2v /content\n",
        "!mv /content/VulnerabilityDetection/Code/myutils.py /content\n",
        "!mv /content/VulnerabilityDetection/Code/data /content"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mK7yJDdr_c9A",
        "outputId": "c06d499a-d7d2-4fec-bf76-557297c90f08"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/w2v/othermodels.rar\n",
            "\n",
            "Extracting  /content/w2v/word2vec_withoutString10-1-200.model            \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-5-200.model            \b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-10-200.model           \b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-30-200.model           \b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-50-200.model           \b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-100-200.model          \b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString10-300-200.model          \b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-1-200.model          \b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-5-200.model          \b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-10-200.model         \b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-30-200.model         \b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-50-200.model         \b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-100-200.model        \b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-300-200.model        \b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withoutString5000-500-200.model        \b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-1-200.model               \b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-5-200.model               \b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-10-200.model              \b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-30-200.model              \b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-50-200.model              \b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-100-200.model             \b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-200-200.model             \b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b\b  OK \n",
            "\n",
            "Would you like to replace the existing file /content/w2v/word2vec_withString10-300-200.model\n",
            "9036021 bytes, modified on 2022-09-12 07:41\n",
            "with a new one\n",
            "9036021 bytes, modified on 2019-11-10 02:28\n",
            "\n",
            "[Y]es, [N]o, [A]ll, n[E]ver, [R]ename, [Q]uit A\n",
            "\n",
            "Extracting  /content/w2v/word2vec_withString10-300-200.model             \b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString10-400-200.model             \b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-1-200.model             \b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-5-200.model             \b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-10-200.model            \b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-30-200.model            \b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-50-200.model            \b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-100-200.model           \b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b\b  OK \n",
            "Extracting  /content/w2v/word2vec_withString5000-300-200.model           \b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ],
      "source": [
        "!unrar e /content/w2v/othermodels.rar /content/w2v"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!unrar e /content/w2v/pythontraining_withString.rar /content/w2v"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ooNq5G2xPxU",
        "outputId": "0389ccf9-a54b-4ce5-e924-3fc96cadac92"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "UNRAR 5.50 freeware      Copyright (c) 1993-2017 Alexander Roshal\n",
            "\n",
            "\n",
            "Extracting from /content/w2v/pythontraining_withString.rar\n",
            "\n",
            "Extracting  /content/w2v/pythontraining_withString_X                     \b\b\b\b  0%\b\b\b\b  1%\b\b\b\b  2%\b\b\b\b  3%\b\b\b\b  4%\b\b\b\b  5%\b\b\b\b  6%\b\b\b\b  7%\b\b\b\b  8%\b\b\b\b  9%\b\b\b\b 10%\b\b\b\b 11%\b\b\b\b 12%\b\b\b\b 13%\b\b\b\b 14%\b\b\b\b 15%\b\b\b\b 16%\b\b\b\b 17%\b\b\b\b 18%\b\b\b\b 19%\b\b\b\b 20%\b\b\b\b 21%\b\b\b\b 22%\b\b\b\b 23%\b\b\b\b 24%\b\b\b\b 25%\b\b\b\b 26%\b\b\b\b 27%\b\b\b\b 28%\b\b\b\b 29%\b\b\b\b 30%\b\b\b\b 31%\b\b\b\b 32%\b\b\b\b 33%\b\b\b\b 34%\b\b\b\b 35%\b\b\b\b 36%\b\b\b\b 37%\b\b\b\b 38%\b\b\b\b 39%\b\b\b\b 40%\b\b\b\b 41%\b\b\b\b 42%\b\b\b\b 43%\b\b\b\b 44%\b\b\b\b 45%\b\b\b\b 46%\b\b\b\b 47%\b\b\b\b 48%\b\b\b\b 49%\b\b\b\b 50%\b\b\b\b 51%\b\b\b\b 52%\b\b\b\b 53%\b\b\b\b 54%\b\b\b\b 55%\b\b\b\b 56%\b\b\b\b 57%\b\b\b\b 58%\b\b\b\b 59%\b\b\b\b 60%\b\b\b\b 61%\b\b\b\b 62%\b\b\b\b 63%\b\b\b\b 64%\b\b\b\b 65%\b\b\b\b 66%\b\b\b\b 67%\b\b\b\b 68%\b\b\b\b 69%\b\b\b\b 70%\b\b\b\b 71%\b\b\b\b 72%\b\b\b\b 73%\b\b\b\b 74%\b\b\b\b 75%\b\b\b\b 76%\b\b\b\b 77%\b\b\b\b 78%\b\b\b\b 79%\b\b\b\b 80%\b\b\b\b 81%\b\b\b\b 82%\b\b\b\b 83%\b\b\b\b 84%\b\b\b\b 85%\b\b\b\b 86%\b\b\b\b 87%\b\b\b\b 88%\b\b\b\b 89%\b\b\b\b 90%\b\b\b\b 91%\b\b\b\b 92%\b\b\b\b 93%\b\b\b\b 94%\b\b\b\b 95%\b\b\b\b 96%\b\b\b\b 97%\b\b\b\b 98%\b\b\b\b 99%\b\b\b\b\b  OK \n",
            "All OK\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "C8KsoN1P-03G"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import myutils\n",
        "import sys\n",
        "import os\n",
        "from sklearn.metrics import accuracy_score \n",
        "from sklearn.metrics import precision_score \n",
        "from sklearn.metrics import recall_score \n",
        "from sklearn.metrics import f1_score \n",
        "from sklearn.utils import class_weight\n",
        "from gensim.models import Word2Vec "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aiCIUM-pmP6O",
        "outputId": "5ab3dacd-c0ff-4ffe-d58f-df976946c0b6"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "id": "kDD_SZfM_7Rg"
      },
      "outputs": [],
      "source": [
        "#paramerters for filtering and creation of samples\n",
        "mode='sql'\n",
        "model_name = 'LSTM'\n",
        "progress = 0\n",
        "count = 0\n",
        "restriction = [20000, 5, 6, 10]\n",
        "step = 5\n",
        "full_length = 200\n",
        "mode_param = str(step)+\"_\"+str(full_length)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "id": "5q_JAclsAXWo"
      },
      "outputs": [],
      "source": [
        "#parameters for w2v model\n",
        "mincount = 5000 #minimum time a word has to appear in the corpus to be in the w2vec model\n",
        "iterationen = 300  #training iterations for the w2v model\n",
        "s = 200 #d\n",
        "w = \"withString\"\n",
        "w2v_name = \"word2vec_\" + w + str(mincount) + \"-\" + str(iterationen) + \"-\" + str(s)\n",
        "w2v_model = 'w2v/'+ w2v_name + \".model\"\n",
        "\n",
        "w2v_model = Word2Vec.load(w2v_model)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "5JaPpNu_Dpeh"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "all_blocks = []\n",
        "with open('data/plain_' + mode, 'r') as infile:\n",
        "  data = json.load(infile)\n",
        "\n",
        "\n",
        "# print(data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "zsOqMIwzEWDB"
      },
      "outputs": [],
      "source": [
        "\n",
        "# allblocks = []\n",
        "# for r in data:\n",
        "#   progress = progress + 1\n",
        "#   for c in data[r]:\n",
        "    \n",
        "#     if \"files\" in data[r][c]:                      \n",
        "#       # if len(data[r][c][\"files\"]) > restriction[3]:\n",
        "#       #   # too many files\n",
        "#       #  continue\n",
        "      \n",
        "#       for f in data[r][c][\"files\"]:\n",
        "        \n",
        "#         # if len(data[r][c][\"files\"][f][\"changes\"]) >= restriction[2]:\n",
        "#         #   #too many changes in a single file\n",
        "#         #   continue\n",
        "        \n",
        "#         if not \"source\" in data[r][c][\"files\"][f]:\n",
        "#           #no sourcecode\n",
        "#           continue\n",
        "        \n",
        "#         if \"source\" in data[r][c][\"files\"][f]:\n",
        "#           sourcecode = data[r][c][\"files\"][f][\"source\"]                          \n",
        "#           # if len(sourcecode) > restriction[0]:\n",
        "#           #   #sourcecode is too long\n",
        "#           #   continue\n",
        "          \n",
        "#           allbadparts = []\n",
        "          \n",
        "#           for change in data[r][c][\"files\"][f][\"changes\"]:\n",
        "#                 #get the modified or removed parts from each change that happened in the commit                  \n",
        "#                 badparts = change[\"badparts\"]\n",
        "#                 count = count + len(badparts)\n",
        "#                 # if len(badparts) > restriction[1]:\n",
        "#                 #   #too many modifications in one change\n",
        "#                 #   break\n",
        "                 \n",
        "                \n",
        "#                 for bad in badparts:\n",
        "#                   #check if they can be found within the file\n",
        "#                   pos = myutils.findposition(bad,sourcecode)\n",
        "#                   if not -1 in pos:\n",
        "#                       allbadparts.append(bad)\n",
        "#                 # if (len(allbadparts) > restriction[2]):\n",
        "#                 #   # too many bad positions in the file\n",
        "#                 #   break\n",
        "#           if(len(allbadparts) > 0):\n",
        "#             # if len(allbadparts) < restriction[2]:\n",
        "#             #   # find the positions of all modified parts\n",
        "#             #   positions = myutils.findpositions(allbadparts,sourcecode)\n",
        "\n",
        "#               #get the file split up in samples\n",
        "#               blocks = myutils.getblocks(sourcecode, positions, step, full_length)\n",
        "              \n",
        "#               for b in blocks:\n",
        "#                   #each is a tuple of code and label\n",
        "#                   allblocks.append(b)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "id": "XHepG1nwMWBF"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torch.utils.data import Dataset\n",
        "from torchtext.transforms import ToTensor, PadTransform\n",
        "import random\n",
        "class MyDataset(Dataset):\n",
        "  def __init__(self, allblocks ,data_split='train', transform=None, target_transform=None):\n",
        "    self.allblocks = allblocks \n",
        "    self.transform = transform\n",
        "    self.target_transform = target_transform\n",
        "    self.data_split=data_split\n",
        "  \n",
        "    keys = []\n",
        "    for i in range(len(self.allblocks)):\n",
        "      keys.append(i)\n",
        "    random.shuffle(keys)\n",
        "    cutoff = round(0.7 * len(keys)) #     70% for the training set\n",
        "    cutoff2 = round(0.85 * len(keys)) #   15% for the validation set and 15% for the final test set\n",
        "    self.keystrain = keys[:cutoff]\n",
        "    self.keysvalid = keys[cutoff:cutoff2]\n",
        "    self.keystest = keys[cutoff2:]\n",
        "\n",
        "    default_idx = self.keystrain[0]\n",
        "    block = self.allblocks[default_idx]\n",
        "    code = block[0]\n",
        "    self.default_token = myutils.getTokens(code)\n",
        "\n",
        "  def __len__(self):\n",
        "    if self.data_split == 'train': \n",
        "      return len(self.keystrain)\n",
        "    elif self.data_split == 'valid':\n",
        "      return len(self.keysvalid)\n",
        "    elif self.data_split == 'test': \n",
        "      return len(self.keystest)\n",
        "    else:\n",
        "      print('Invalid split')\n",
        "      \n",
        "\n",
        "\n",
        "  def __getitem__(self, idx):\n",
        "    word_vectors = w2v_model.wv\n",
        "    if self.data_split == 'train': \n",
        "      key_idx = self.keystrain[idx]\n",
        "    elif self.data_split == 'valid':\n",
        "      key_idx = self.keysvalid[idx]\n",
        "    elif self.data_split == 'test':\n",
        "      key_idx = self.keystest[idx]\n",
        "    block = self.allblocks[key_idx]\n",
        "    code = block[0]\n",
        "    token = myutils.getTokens(code) #get all single tokens from the snippet of code\n",
        "    if(len(token) == 0): \n",
        "      print(len(token))\n",
        "      token = self.default_token\n",
        "\n",
        "    vectorlist = []\n",
        "    if block[1] == 1: \n",
        "      label = 0 \n",
        "    else: \n",
        "      label = 1\n",
        "    for t in token: #convert all tokens into their word2vec vector representation\n",
        "      if t in word_vectors.vocab and t != \" \":\n",
        "        word_vector = w2v_model[t]\n",
        "        vectorlist.append(word_vector) \n",
        "    vectorlist = torch.tensor(vectorlist)\n",
        "    if self.transform:\n",
        "      vectorlist = self.transform(vectorlist)\n",
        "    if self.target_transform:\n",
        "      label = self.target_transform(label)\n",
        "    return vectorlist, label \n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "36IgdIZUteuH"
      },
      "outputs": [],
      "source": [
        "# from torchtext.transforms import ToTensor, PadTransform\n",
        "\n",
        "# train_dataset = MyDataset(\n",
        "#     allblocks=allblocks,\n",
        "#     data_split='train',\n",
        "# )\n",
        "\n",
        "# valid_dataset = MyDataset(\n",
        "#     allblocks=allblocks,\n",
        "#     data_split='valid'\n",
        "# )\n",
        "\n",
        "# test_dataset = MyDataset(\n",
        "#     allblocks=allblocks,\n",
        "#     data_split='test'\n",
        "# )\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data_path = '/content/drive/MyDrive/data'\n",
        "isFiltered = False \n",
        "name = '_filtered' if isFiltered else '' \n",
        "# torch.save(train_dataset, f'{data_path}/train_data_{mode}{name}.pth')\n",
        "# torch.save(valid_dataset, f'{data_path}/valid_data_{mode}{name}.pth')\n",
        "# torch.save(test_dataset, f'{data_path}/test_data_{mode}{name}.pth')"
      ],
      "metadata": {
        "id": "kfNdCdVPoxck"
      },
      "execution_count": 85,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_dataset = torch.load(f'{data_path}/train_data_{mode}{name}.pth')\n",
        "valid_dataset = torch.load(f'{data_path}/valid_data_{mode}{name}.pth')\n",
        "test_dataset = torch.load(f'{data_path}/test_data_{mode}{name}.pth')"
      ],
      "metadata": {
        "id": "tONl2Kwxo5cD"
      },
      "execution_count": 86,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "id": "OBBHk8JJDi8r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "2ed03507-6232-4297-c741-3fa66724802e"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "199219\n",
            "42690\n",
            "42690\n"
          ]
        }
      ],
      "source": [
        "print(len(train_dataset))\n",
        "print(len(valid_dataset))\n",
        "print(len(test_dataset))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "id": "7tFJ5j8gG1xb",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d5f0edbe-a730-486f-d5f6-7d5976eafbd2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([59, 200])\n",
            "torch.Size([37, 200])\n",
            "torch.Size([40, 200])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ],
      "source": [
        "print(train_dataset[10][0].shape)\n",
        "print(valid_dataset[10][0].shape)\n",
        "print(test_dataset[10][0].shape)"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "Xg7UsiyhQLlJ"
      },
      "execution_count": 88,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 89,
      "metadata": {
        "id": "yMUbdH6lIBOe"
      },
      "outputs": [],
      "source": [
        "from torch.nn.utils.rnn import pad_sequence\n",
        "batch_size = 128 \n",
        "class MyCollate:\n",
        "    def __init__(self, pad_idx):\n",
        "        self.pad_idx = pad_idx\n",
        "        \n",
        "    \n",
        "    def __call__(self, batch):\n",
        "      source = []\n",
        "      target = []\n",
        "      for i in range(len(batch)):\n",
        "        if batch[i][0].shape[0] != 0:\n",
        "          source.append(batch[i][0]) \n",
        "          target.append(batch[i][1])\n",
        "\n",
        "      for i in range(batch_size - len(source)):\n",
        "        source.append(source[-1])\n",
        "        target.append(target[-1])\n",
        "      \n",
        "      source = pad_sequence(source, batch_first=True, padding_value = self.pad_idx) \n",
        "      return source, target "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 90,
      "metadata": {
        "id": "ZNZJPHN6LMUs"
      },
      "outputs": [],
      "source": [
        "from torch.utils.data import DataLoader \n",
        "\n",
        "def get_data_loader(dataset, batch_size, num_workers=0, shuffle=True, pin_memory=True): #increase num_workers according to CPU\n",
        "    pad_idx = 0 \n",
        "    loader = DataLoader(\n",
        "        dataset,\n",
        "        batch_size = batch_size, \n",
        "        num_workers = num_workers,\n",
        "        shuffle=shuffle,\n",
        "        pin_memory=pin_memory, \n",
        "        collate_fn = MyCollate(pad_idx=pad_idx)\n",
        "    ) \n",
        "    return loader"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "id": "vua3uGG_NeaD"
      },
      "outputs": [],
      "source": [
        " \n",
        "train_loader = get_data_loader(train_dataset, batch_size=batch_size )\n",
        "valid_loader = get_data_loader(valid_dataset, batch_size=batch_size)\n",
        "test_loader = get_data_loader(test_dataset, batch_size=batch_size)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for step, data in enumerate(train_loader):\n",
        "  print(data[0].shape)\n",
        "  break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfpYlYtP6JfI",
        "outputId": "fb564245-c371-4a79-ad2f-5db7c2390c8b"
      },
      "execution_count": 92,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([128, 72, 200])\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 70,
      "metadata": {
        "id": "0atpWq-wmyFv"
      },
      "outputs": [],
      "source": [
        "cudaEnabled = True "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils.class_weight import compute_class_weight\n",
        "import numpy as np\n",
        "y = np.array([])\n",
        "y = np.concatenate([label for item, label in train_loader])\n",
        "class_weights = compute_class_weight(class_weight='balanced', classes=np.unique(y), y=y)"
      ],
      "metadata": {
        "id": "DgtM2lniUb8Y",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a0609b1c-f141-4434-ae23-b2657c35a41f"
      },
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class_weights"
      ],
      "metadata": {
        "id": "3waIWlKvaJEd",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "efbf6f55-7b88-41fe-eae8-02d9f44a1574"
      },
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([ 0.51543491, 16.69705094])"
            ]
          },
          "metadata": {},
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 153,
      "metadata": {
        "id": "YNnxQiziP1XZ"
      },
      "outputs": [],
      "source": [
        "class MyGRUModel(nn.Module):\n",
        "  def __init__(self, hidden_size=200, num_gru_layers=1, gru_bidirectional=False):\n",
        "    super(MyGRUModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = w2v_model\n",
        "    self.num_gru_layers = num_gru_layers\n",
        "    self.gru_bidirectional = gru_bidirectional\n",
        "    self.D = 2 if gru_bidirectional else 1\n",
        "    self.model= nn.GRU(\n",
        "        hidden_size,\n",
        "        hidden_size,\n",
        "        dropout=0.2,\n",
        "        batch_first=True, \n",
        "        num_layers=self.num_gru_layers,\n",
        "        bidirectional=self.gru_bidirectional\n",
        "    )\n",
        "    self.out = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    hidden = hidden.cuda()\n",
        "    output, hidden = self.model(input, hidden )\n",
        "    output = self.out(output)\n",
        "    output = self.sigmoid(output)\n",
        "    return output, hidden\n",
        "  \n",
        "  def initHidden(self, batch_size=1):\n",
        "    hidden = torch.zeros(self.D * self.num_gru_layers, batch_size ,self.hidden_size)\n",
        "    if cudaEnabled: hidden = hidden.cuda()\n",
        "    return hidden \n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class MyLSTMModel(nn.Module):\n",
        "  def __init__(self, hidden_size=200, num_lstm_layers=1, lstm_bidirectional=False):\n",
        "    super(MyLSTMModel, self).__init__()\n",
        "    self.hidden_size = hidden_size\n",
        "    self.embedding = w2v_model\n",
        "    self.num_lstm_layers = num_lstm_layers\n",
        "    self.lstm_bidirectional = lstm_bidirectional\n",
        "    self.D = 2 if lstm_bidirectional else 1\n",
        "    self.model= nn.LSTM(\n",
        "        hidden_size,\n",
        "        hidden_size,\n",
        "        dropout=0.2,\n",
        "        batch_first=True, \n",
        "        num_layers=self.num_lstm_layers,\n",
        "        bidirectional=self.lstm_bidirectional\n",
        "    )\n",
        "    self.out = nn.Linear(hidden_size, 1)\n",
        "    self.sigmoid = nn.Sigmoid()\n",
        "  \n",
        "  def forward(self, input, hidden):\n",
        "    (h0, c0) = hidden\n",
        "    h0 = h0.cuda()\n",
        "    c0 = c0.cuda()\n",
        "    output, (hn, cn) = self.model(input, (h0, c0))\n",
        "    output = self.out(output)\n",
        "    output = self.sigmoid(output)\n",
        "    return output, (hn, cn) \n",
        "  \n",
        "  def initHidden(self, batch_size=1):\n",
        "    h0 = torch.zeros(self.D * self.num_lstm_layers, batch_size ,self.hidden_size)\n",
        "    c0 = torch.zeros(self.D * self.num_lstm_layers, batch_size ,self.hidden_size)\n",
        "    if cudaEnabled: \n",
        "      h0 = h0.cuda()\n",
        "      c0 = h0.cuda()\n",
        "    return h0, c0 \n",
        "   "
      ],
      "metadata": {
        "id": "EBcDhq9XygQZ"
      },
      "execution_count": 154,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 155,
      "metadata": {
        "id": "r4WgITRxRcTq"
      },
      "outputs": [],
      "source": [
        "model = MyGRUModel() if model_name == 'GRU' else MyLSTMModel()\n",
        "if cudaEnabled: model = model.cuda()\n",
        "\n",
        "# model.load_state_dict(torch.load(f'/content/drive/MyDrive/models/model_{model_name}_{mode}.pth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 156,
      "metadata": {
        "id": "fnk6ty7oU-pE"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import time\n",
        "print_every = 1000\n",
        "plot_every = 50000\n",
        "\n",
        "def timeSince(since):\n",
        "  now = time.time()\n",
        "  s = now - since\n",
        "  m = math.floor(s/60)\n",
        "  s -= m * 60\n",
        "  return f'{m}m {math.floor(s)}s' \n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def weighted_binary_cross_entropy(output, target, weights=None):\n",
        "    # print(output, target)\n",
        "    if weights is not None:\n",
        "        assert len(weights) == 2\n",
        "        loss = weights[1] * (target * torch.log(output)) + \\\n",
        "               weights[0] * ((1 - target) * torch.log(1 - output))\n",
        "    else:\n",
        "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
        "\n",
        "    return torch.neg(torch.mean(loss))"
      ],
      "metadata": {
        "id": "67L3u1L5TaZo"
      },
      "execution_count": 157,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 158,
      "metadata": {
        "id": "sTANYdyqup0J"
      },
      "outputs": [],
      "source": [
        "\n",
        "from torchmetrics import F1Score, Precision, Recall\n",
        "def evaluate(model, is_test=False):\n",
        "  print(50*'-' + 'evaluating' + 50*'-')\n",
        "  targets = torch.tensor([]).cuda() \n",
        "  preds = torch.tensor([]).cuda() \n",
        "  start = time.time()\n",
        "  all_losses = []\n",
        "\n",
        "  loader = test_loader if is_test else valid_loader\n",
        "  \n",
        "  with torch.no_grad():\n",
        "    print_count = 0 \n",
        "    for iter, (input , labels) in enumerate(test_loader):\n",
        "\n",
        "      hidden = model.initHidden(batch_size=batch_size)\n",
        "      label_tensor = torch.tensor(labels)\n",
        "\n",
        "      if cudaEnabled: \n",
        "        label_tensor = label_tensor.cuda()\n",
        "        input = input.cuda()\n",
        "\n",
        "      targets = torch.cat((targets, torch.tensor(label_tensor)))\n",
        "      output, hidden = model(input, hidden)\n",
        "      final_output = output[:, -1, :].T\n",
        "      loss = weighted_binary_cross_entropy(final_output , label_tensor, weights=class_weights)\n",
        "      all_losses.append(loss)\n",
        "      preds = torch.cat((preds, final_output), 1)\n",
        "\n",
        "      if iter * batch_size > print_every * print_count:\n",
        "        print_count += 1\n",
        "        print(f'iter: {iter * batch_size} {math.floor(iter * batch_size/len(valid_dataset) * 100)}% ({timeSince(start)})')\n",
        "\n",
        "    eval_loss = torch.mean(torch.tensor(all_losses))\n",
        "    preds = torch.squeeze(preds)\n",
        "    targets = targets.int()\n",
        "  if cudaEnabled:\n",
        "    preds = torch.tensor(preds).cuda()\n",
        "    targets = torch.tensor(targets).cuda()\n",
        "    f1 = F1Score(num_classes=1).cuda()\n",
        "    precision = Precision(num_classes=1).cuda()\n",
        "    recall = Recall(num_classes=1).cuda()\n",
        "  else:\n",
        "    preds = torch.tensor(preds)\n",
        "    targets = torch.tensor(targets)\n",
        "    f1 = F1Score(num_classes=1)\n",
        "    precision = Precision(num_classes=1)\n",
        "    recall = Recall(num_classes=1)\n",
        "\n",
        "  f1_score = f1(preds, targets)\n",
        "  precision_score = precision(preds, targets)\n",
        "  recall_score = recall(preds, targets)\n",
        "  print(f'f1 score: {f1_score}')\n",
        "  print(f'precison score: {precision_score}')\n",
        "  print(f'recall score: {recall_score}')\n",
        "\n",
        "  return eval_loss, f1_score, precision_score, recall_score\n",
        "\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 150,
      "metadata": {
        "id": "68E3FnpixMZO",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aa10ad85-6652-40c9-f4b7-4aa33bb19fde"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------evaluating--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 2s)\n",
            "iter: 3072 7% (0m 2s)\n",
            "iter: 4096 9% (0m 3s)\n",
            "iter: 5120 11% (0m 4s)\n",
            "iter: 6016 14% (0m 5s)\n",
            "iter: 7040 16% (0m 6s)\n",
            "iter: 8064 18% (0m 7s)\n",
            "iter: 9088 21% (0m 8s)\n",
            "iter: 10112 23% (0m 9s)\n",
            "iter: 11008 25% (0m 10s)\n",
            "iter: 12032 28% (0m 11s)\n",
            "iter: 13056 30% (0m 12s)\n",
            "iter: 14080 32% (0m 13s)\n",
            "iter: 15104 35% (0m 14s)\n",
            "iter: 16128 37% (0m 15s)\n",
            "iter: 17024 39% (0m 15s)\n",
            "iter: 18048 42% (0m 16s)\n",
            "iter: 19072 44% (0m 17s)\n",
            "iter: 20096 47% (0m 18s)\n",
            "iter: 21120 49% (0m 19s)\n",
            "iter: 22016 51% (0m 20s)\n",
            "iter: 23040 53% (0m 21s)\n",
            "iter: 24064 56% (0m 22s)\n",
            "iter: 25088 58% (0m 23s)\n",
            "iter: 26112 61% (0m 24s)\n",
            "iter: 27008 63% (0m 24s)\n",
            "iter: 28032 65% (0m 25s)\n",
            "iter: 29056 68% (0m 26s)\n",
            "iter: 30080 70% (0m 27s)\n",
            "iter: 31104 72% (0m 28s)\n",
            "iter: 32128 75% (0m 29s)\n",
            "iter: 33024 77% (0m 30s)\n",
            "iter: 34048 79% (0m 31s)\n",
            "iter: 35072 82% (0m 33s)\n",
            "iter: 36096 84% (0m 33s)\n",
            "iter: 37120 86% (0m 34s)\n",
            "iter: 38016 89% (0m 35s)\n",
            "iter: 39040 91% (0m 36s)\n",
            "iter: 40064 93% (0m 37s)\n",
            "iter: 41088 96% (0m 38s)\n",
            "iter: 42112 98% (0m 39s)\n",
            "f1 score: 0.01338199619203806\n",
            "precison score: 0.03678929805755615\n",
            "recall score: 0.008178438991308212\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.7104),\n",
              " tensor(0.0134, device='cuda:0'),\n",
              " tensor(0.0368, device='cuda:0'),\n",
              " tensor(0.0082, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 150
        }
      ],
      "source": [
        "evaluate(model)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 159,
      "metadata": {
        "id": "OBc6y15YU3kv"
      },
      "outputs": [],
      "source": [
        "import torch.optim as optim\n",
        "learning_rate = 0.0005\n",
        "max_epochs = 10\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "def train(input_tensor, label_tensor):\n",
        "  hidden = model.initHidden(batch_size=batch_size)\n",
        "  model.zero_grad()\n",
        "  label_tensor = torch.tensor([label_tensor])\n",
        "\n",
        "  if cudaEnabled: \n",
        "    label_tensor = label_tensor.cuda()\n",
        "    input = input_tensor.cuda()\n",
        "\n",
        "  output, hidden = model(input, hidden)\n",
        "  final_output = output[:, -1, :].T\n",
        "  loss = weighted_binary_cross_entropy(final_output , label_tensor, weights=class_weights)\n",
        "  loss.backward()\n",
        "  optimizer.step()\n",
        "  return final_output, loss.item()\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "current_loss = 0\n",
        "all_lstm_losses = []\n",
        "all_eval_losses = []\n",
        "max_epochs = 10\n",
        "n_iter = max_epochs * len(train_dataset)"
      ],
      "metadata": {
        "id": "j0PNWa51se9E"
      },
      "execution_count": 160,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qpLk9VpEkY4M",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "16c7df7b-8878-48c6-e20e-2be262902aed"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "epoch: 0 iter: 1024 0% (0m 1s) 0.5337 / f1 score: 0.03100775182247162\n",
            "epoch: 0 iter: 2048 1% (0m 2s) 0.7883 / f1 score: 0.07633588463068008\n",
            "epoch: 0 iter: 3072 1% (0m 3s) 0.875 / f1 score: 0.09090908616781235\n",
            "epoch: 0 iter: 4096 2% (0m 4s) 0.5369 / f1 score: 0.03100775182247162\n",
            "epoch: 0 iter: 5120 2% (0m 5s) 0.6169 / f1 score: 0.04724409431219101\n",
            "epoch: 0 iter: 6016 3% (0m 6s) 0.7087 / f1 score: 0.04615384712815285\n",
            "epoch: 0 iter: 7040 3% (0m 7s) 1.2218 / f1 score: 0.145985409617424\n",
            "epoch: 0 iter: 8064 4% (0m 8s) 0.5321 / f1 score: 0.03100775182247162\n",
            "epoch: 0 iter: 9088 4% (0m 9s) 0.7928 / f1 score: 0.0\n",
            "epoch: 0 iter: 10112 5% (0m 10s) 0.7007 / f1 score: 0.0\n",
            "epoch: 0 iter: 11008 5% (0m 11s) 0.7056 / f1 score: 0.0\n",
            "epoch: 0 iter: 12032 6% (0m 12s) 0.6129 / f1 score: 0.0\n",
            "epoch: 0 iter: 13056 6% (0m 13s) 1.0618 / f1 score: 0.0\n",
            "epoch: 0 iter: 14080 7% (0m 14s) 0.6175 / f1 score: 0.04651162773370743\n",
            "epoch: 0 iter: 15104 7% (0m 15s) 0.7031 / f1 score: 0.0625\n",
            "epoch: 0 iter: 16128 8% (0m 17s) 0.6199 / f1 score: 0.0476190485060215\n",
            "epoch: 0 iter: 17024 8% (0m 17s) 0.6158 / f1 score: 0.04800000414252281\n",
            "epoch: 0 iter: 18048 9% (0m 18s) 0.7884 / f1 score: 0.07633588463068008\n",
            "epoch: 0 iter: 19072 9% (0m 20s) 0.8693 / f1 score: 0.09302325546741486\n",
            "epoch: 0 iter: 20096 10% (0m 21s) 0.7045 / f1 score: 0.062015511095523834\n",
            "epoch: 0 iter: 21120 10% (0m 22s) 0.5368 / f1 score: 0.0317460298538208\n",
            "epoch: 0 iter: 22016 11% (0m 23s) 0.4553 / f1 score: 0.015625\n",
            "epoch: 0 iter: 23040 11% (0m 24s) 0.6194 / f1 score: 0.046875\n",
            "epoch: 0 iter: 24064 12% (0m 25s) 0.7884 / f1 score: 0.07633588463068008\n",
            "epoch: 0 iter: 25088 12% (0m 26s) 0.5961 / f1 score: 0.0\n",
            "epoch: 0 iter: 26112 13% (0m 27s) 0.7062 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 27008 13% (0m 28s) 0.4529 / f1 score: 0.015748033300042152\n",
            "epoch: 0 iter: 28032 14% (0m 29s) 1.0454 / f1 score: 0.11851852387189865\n",
            "epoch: 0 iter: 29056 14% (0m 30s) 0.6211 / f1 score: 0.04615384712815285\n",
            "epoch: 0 iter: 30080 15% (0m 31s) 0.7915 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 31104 15% (0m 32s) 0.7918 / f1 score: 0.07633588463068008\n",
            "epoch: 0 iter: 32128 16% (0m 33s) 0.7931 / f1 score: 0.07751937955617905\n",
            "epoch: 0 iter: 33024 16% (0m 34s) 0.7935 / f1 score: 0.07633588463068008\n",
            "epoch: 0 iter: 34048 17% (0m 35s) 0.6196 / f1 score: 0.04724409431219101\n",
            "epoch: 0 iter: 35072 17% (0m 36s) 0.7967 / f1 score: 0.0\n",
            "epoch: 0 iter: 36096 18% (0m 37s) 0.7971 / f1 score: 0.0\n",
            "epoch: 0 iter: 37120 18% (0m 38s) 0.8857 / f1 score: 0.0\n",
            "epoch: 0 iter: 38016 19% (0m 39s) 0.894 / f1 score: 0.0\n",
            "epoch: 0 iter: 39040 19% (0m 40s) 1.2405 / f1 score: 0.0\n",
            "epoch: 0 iter: 40064 20% (0m 42s) 0.7938 / f1 score: 0.0\n",
            "epoch: 0 iter: 41088 20% (0m 43s) 0.7939 / f1 score: 0.0\n",
            "epoch: 0 iter: 42112 21% (0m 44s) 0.5309 / f1 score: 0.0\n",
            "epoch: 0 iter: 43008 21% (0m 45s) 0.8818 / f1 score: 0.0\n",
            "epoch: 0 iter: 44032 22% (0m 46s) 0.7939 / f1 score: 0.0\n",
            "epoch: 0 iter: 45056 22% (0m 47s) 0.7313 / f1 score: 0.3333333134651184\n",
            "epoch: 0 iter: 46080 23% (0m 48s) 0.8848 / f1 score: 0.0\n",
            "epoch: 0 iter: 47104 23% (0m 49s) 0.5483 / f1 score: 0.5\n",
            "epoch: 0 iter: 48128 24% (0m 50s) 0.7061 / f1 score: 0.0\n",
            "epoch: 0 iter: 49024 24% (0m 51s) 1.0618 / f1 score: 0.0\n",
            "epoch: 0 iter: 50048 25% (0m 52s) 0.6169 / f1 score: 0.0\n",
            "--------------------------------------------------evaluating--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 1s)\n",
            "iter: 3072 7% (0m 2s)\n",
            "iter: 4096 9% (0m 3s)\n",
            "iter: 5120 11% (0m 4s)\n",
            "iter: 6016 14% (0m 5s)\n",
            "iter: 7040 16% (0m 6s)\n",
            "iter: 8064 18% (0m 7s)\n",
            "iter: 9088 21% (0m 8s)\n",
            "iter: 10112 23% (0m 9s)\n",
            "iter: 11008 25% (0m 10s)\n",
            "iter: 12032 28% (0m 11s)\n",
            "iter: 13056 30% (0m 12s)\n",
            "iter: 14080 32% (0m 12s)\n",
            "iter: 15104 35% (0m 13s)\n",
            "iter: 16128 37% (0m 14s)\n",
            "iter: 17024 39% (0m 15s)\n",
            "iter: 18048 42% (0m 16s)\n",
            "iter: 19072 44% (0m 17s)\n",
            "iter: 20096 47% (0m 18s)\n",
            "iter: 21120 49% (0m 19s)\n",
            "iter: 22016 51% (0m 20s)\n",
            "iter: 23040 53% (0m 21s)\n",
            "iter: 24064 56% (0m 22s)\n",
            "iter: 25088 58% (0m 23s)\n",
            "iter: 26112 61% (0m 23s)\n",
            "iter: 27008 63% (0m 24s)\n",
            "iter: 28032 65% (0m 25s)\n",
            "iter: 29056 68% (0m 26s)\n",
            "iter: 30080 70% (0m 27s)\n",
            "iter: 31104 72% (0m 28s)\n",
            "iter: 32128 75% (0m 29s)\n",
            "iter: 33024 77% (0m 30s)\n",
            "iter: 34048 79% (0m 31s)\n",
            "iter: 35072 82% (0m 32s)\n",
            "iter: 36096 84% (0m 33s)\n",
            "iter: 37120 86% (0m 34s)\n",
            "iter: 38016 89% (0m 34s)\n",
            "iter: 39040 91% (0m 35s)\n",
            "iter: 40064 93% (0m 36s)\n",
            "iter: 41088 96% (0m 37s)\n",
            "iter: 42112 98% (0m 38s)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "f1 score: 0.005912786349654198\n",
            "precison score: 0.5\n",
            "recall score: 0.0029739777091890574\n",
            "epoch: 0 iter: 51072 25% (1m 32s) 0.8827 / f1 score: 0.0\n",
            "epoch: 0 iter: 52096 26% (1m 33s) 0.9751 / f1 score: 0.0\n",
            "epoch: 0 iter: 53120 26% (1m 34s) 0.619 / f1 score: 0.04615384712815285\n",
            "epoch: 0 iter: 54016 27% (1m 35s) 0.7922 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 55040 27% (1m 36s) 0.5276 / f1 score: 0.03539822995662689\n",
            "epoch: 0 iter: 56064 28% (1m 37s) 0.7069 / f1 score: 0.05042016878724098\n",
            "epoch: 0 iter: 57088 28% (1m 38s) 0.4645 / f1 score: 0.0\n",
            "epoch: 0 iter: 58112 29% (1m 39s) 0.7048 / f1 score: 0.07207206636667252\n",
            "epoch: 0 iter: 59008 29% (1m 40s) 0.6127 / f1 score: 0.0\n",
            "epoch: 0 iter: 60032 30% (1m 42s) 0.6169 / f1 score: 0.0\n",
            "epoch: 0 iter: 61056 30% (1m 43s) 0.4389 / f1 score: 0.0\n",
            "epoch: 0 iter: 62080 31% (1m 44s) 0.6235 / f1 score: 0.0\n",
            "epoch: 0 iter: 63104 31% (1m 45s) 1.3199 / f1 score: 0.0\n",
            "epoch: 0 iter: 64128 32% (1m 46s) 0.5306 / f1 score: 0.03305785357952118\n",
            "epoch: 0 iter: 65024 32% (1m 47s) 0.6189 / f1 score: 0.04651162773370743\n",
            "epoch: 0 iter: 66048 33% (1m 48s) 0.7931 / f1 score: 0.08000000566244125\n",
            "epoch: 0 iter: 67072 33% (1m 49s) 0.7067 / f1 score: 0.062015511095523834\n",
            "epoch: 0 iter: 68096 34% (1m 50s) 0.7933 / f1 score: 0.0624999962747097\n",
            "epoch: 0 iter: 69120 34% (1m 51s) 0.9675 / f1 score: 0.10447761416435242\n",
            "epoch: 0 iter: 70016 35% (1m 52s) 0.6389 / f1 score: 0.0317460335791111\n",
            "epoch: 0 iter: 71040 35% (1m 53s) 0.7933 / f1 score: 0.07633588463068008\n",
            "epoch: 0 iter: 72064 36% (1m 54s) 0.5335 / f1 score: 0.03100775182247162\n",
            "epoch: 0 iter: 73088 36% (1m 55s) 0.3591 / f1 score: 0.0\n",
            "epoch: 0 iter: 74112 37% (1m 56s) 0.7227 / f1 score: 0.0521739162504673\n",
            "epoch: 0 iter: 75008 37% (1m 57s) 0.7935 / f1 score: 0.0\n",
            "epoch: 0 iter: 76032 38% (1m 58s) 0.6173 / f1 score: 0.0\n",
            "epoch: 0 iter: 77056 38% (1m 59s) 0.6173 / f1 score: 0.0\n",
            "epoch: 0 iter: 78080 39% (2m 0s) 0.708 / f1 score: 0.0\n",
            "epoch: 0 iter: 79104 39% (2m 1s) 0.7053 / f1 score: 0.0\n",
            "epoch: 0 iter: 80128 40% (2m 2s) 0.8866 / f1 score: 0.0\n",
            "epoch: 0 iter: 81024 40% (2m 3s) 0.5219 / f1 score: 0.0\n",
            "epoch: 0 iter: 82048 41% (2m 4s) 0.6165 / f1 score: 0.0\n",
            "epoch: 0 iter: 83072 41% (2m 6s) 0.703 / f1 score: 0.0\n",
            "epoch: 0 iter: 84096 42% (2m 7s) 0.5264 / f1 score: 0.0\n",
            "epoch: 0 iter: 85120 42% (2m 8s) 0.7888 / f1 score: 0.0\n",
            "epoch: 0 iter: 86016 43% (2m 9s) 0.4392 / f1 score: 0.0\n",
            "epoch: 0 iter: 87040 43% (2m 10s) 0.7948 / f1 score: 0.0\n",
            "epoch: 0 iter: 88064 44% (2m 11s) 0.6168 / f1 score: 0.0\n",
            "epoch: 0 iter: 89088 44% (2m 12s) 0.4383 / f1 score: 0.0\n",
            "epoch: 0 iter: 90112 45% (2m 13s) 0.7005 / f1 score: 0.0\n",
            "epoch: 0 iter: 91008 45% (2m 14s) 0.7336 / f1 score: 0.0\n",
            "epoch: 0 iter: 92032 46% (2m 15s) 0.6168 / f1 score: 0.0\n",
            "epoch: 0 iter: 93056 46% (2m 16s) 0.6167 / f1 score: 0.0\n",
            "epoch: 0 iter: 94080 47% (2m 17s) 0.4369 / f1 score: 0.0\n",
            "epoch: 0 iter: 95104 47% (2m 18s) 0.8853 / f1 score: 0.0\n",
            "epoch: 0 iter: 96128 48% (2m 19s) 0.7967 / f1 score: 0.0\n",
            "epoch: 0 iter: 97024 48% (2m 20s) 0.7924 / f1 score: 0.3333333134651184\n",
            "epoch: 0 iter: 98048 49% (2m 21s) 0.8879 / f1 score: 0.0\n",
            "epoch: 0 iter: 99072 49% (2m 22s) 0.6673 / f1 score: 0.0\n",
            "epoch: 0 iter: 100096 50% (2m 23s) 0.6172 / f1 score: 0.0\n",
            "--------------------------------------------------evaluating--------------------------------------------------\n",
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 1s)\n",
            "iter: 3072 7% (0m 2s)\n",
            "iter: 4096 9% (0m 3s)\n",
            "iter: 5120 11% (0m 4s)\n",
            "iter: 6016 14% (0m 5s)\n",
            "iter: 7040 16% (0m 6s)\n",
            "iter: 8064 18% (0m 7s)\n",
            "iter: 9088 21% (0m 8s)\n",
            "iter: 10112 23% (0m 9s)\n",
            "iter: 11008 25% (0m 10s)\n",
            "iter: 12032 28% (0m 11s)\n",
            "iter: 13056 30% (0m 11s)\n",
            "iter: 14080 32% (0m 12s)\n",
            "iter: 15104 35% (0m 13s)\n",
            "iter: 16128 37% (0m 14s)\n",
            "iter: 17024 39% (0m 15s)\n",
            "iter: 18048 42% (0m 16s)\n",
            "iter: 19072 44% (0m 17s)\n",
            "iter: 20096 47% (0m 18s)\n",
            "iter: 21120 49% (0m 19s)\n",
            "iter: 22016 51% (0m 20s)\n",
            "iter: 23040 53% (0m 21s)\n",
            "iter: 24064 56% (0m 22s)\n",
            "iter: 25088 58% (0m 23s)\n",
            "iter: 26112 61% (0m 24s)\n",
            "iter: 27008 63% (0m 24s)\n",
            "iter: 28032 65% (0m 25s)\n",
            "iter: 29056 68% (0m 26s)\n",
            "iter: 30080 70% (0m 27s)\n",
            "iter: 31104 72% (0m 28s)\n",
            "iter: 32128 75% (0m 29s)\n",
            "iter: 33024 77% (0m 30s)\n",
            "iter: 34048 79% (0m 31s)\n",
            "iter: 35072 82% (0m 32s)\n",
            "iter: 36096 84% (0m 33s)\n",
            "iter: 37120 86% (0m 34s)\n",
            "iter: 38016 89% (0m 34s)\n",
            "iter: 39040 91% (0m 35s)\n",
            "iter: 40064 93% (0m 36s)\n",
            "iter: 41088 96% (0m 37s)\n",
            "iter: 42112 98% (0m 38s)\n",
            "f1 score: 0.02322404272854328\n",
            "precison score: 0.1428571492433548\n",
            "recall score: 0.012639405205845833\n",
            "epoch: 0 iter: 101120 50% (3m 3s) 0.6176 / f1 score: 0.0\n",
            "epoch: 0 iter: 102016 51% (3m 4s) 0.8832 / f1 score: 0.0\n",
            "epoch: 0 iter: 103040 51% (3m 5s) 0.7935 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 104064 52% (3m 6s) 0.8776 / f1 score: 0.09022556245326996\n",
            "epoch: 0 iter: 105088 52% (3m 7s) 0.7084 / f1 score: 0.06060606241226196\n",
            "epoch: 0 iter: 106112 53% (3m 8s) 0.7066 / f1 score: 0.061538465321063995\n",
            "epoch: 0 iter: 107008 53% (3m 9s) 0.8124 / f1 score: 0.08955223858356476\n",
            "epoch: 0 iter: 108032 54% (3m 10s) 0.7064 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 109056 54% (3m 11s) 0.8761 / f1 score: 0.09090908616781235\n",
            "epoch: 0 iter: 110080 55% (3m 12s) 0.7069 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 111104 55% (3m 13s) 0.6219 / f1 score: 0.04615384712815285\n",
            "epoch: 0 iter: 112128 56% (3m 15s) 0.7895 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 113024 56% (3m 15s) 0.789 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 114048 57% (3m 17s) 0.7082 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 115072 57% (3m 18s) 0.7072 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 116096 58% (3m 19s) 0.7935 / f1 score: 0.07518796622753143\n",
            "epoch: 0 iter: 117120 58% (3m 20s) 0.7927 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 118016 59% (3m 21s) 0.6209 / f1 score: 0.04651162773370743\n",
            "epoch: 0 iter: 119040 59% (3m 22s) 0.7069 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 120064 60% (3m 23s) 0.6219 / f1 score: 0.04580152779817581\n",
            "epoch: 0 iter: 121088 60% (3m 24s) 0.5322 / f1 score: 0.0317460298538208\n",
            "epoch: 0 iter: 122112 61% (3m 25s) 0.5319 / f1 score: 0.03305785357952118\n",
            "epoch: 0 iter: 123008 61% (3m 26s) 0.7078 / f1 score: 0.0\n",
            "epoch: 0 iter: 124032 62% (3m 27s) 0.972 / f1 score: 0.0\n",
            "epoch: 0 iter: 125056 62% (3m 28s) 0.7953 / f1 score: 0.0\n",
            "epoch: 0 iter: 126080 63% (3m 29s) 0.8876 / f1 score: 0.0\n",
            "epoch: 0 iter: 127104 63% (3m 30s) 0.5296 / f1 score: 0.0\n",
            "epoch: 0 iter: 128128 64% (3m 31s) 0.7086 / f1 score: 0.0\n",
            "epoch: 0 iter: 129024 64% (3m 32s) 0.7949 / f1 score: 0.0\n",
            "epoch: 0 iter: 130048 65% (3m 33s) 0.5307 / f1 score: 0.0\n",
            "epoch: 0 iter: 131072 65% (3m 34s) 0.6189 / f1 score: 0.0\n",
            "epoch: 0 iter: 132096 66% (3m 35s) 0.8843 / f1 score: 0.0\n",
            "epoch: 0 iter: 133120 66% (3m 36s) 0.7082 / f1 score: 0.0\n",
            "epoch: 0 iter: 134016 67% (3m 37s) 0.5293 / f1 score: 0.0\n",
            "epoch: 0 iter: 135040 67% (3m 38s) 0.4413 / f1 score: 0.0\n",
            "epoch: 0 iter: 136064 68% (3m 39s) 0.7069 / f1 score: 0.0\n",
            "epoch: 0 iter: 137088 68% (3m 40s) 0.7972 / f1 score: 0.0\n",
            "epoch: 0 iter: 138112 69% (3m 41s) 0.5278 / f1 score: 0.0\n",
            "epoch: 0 iter: 139008 69% (3m 42s) 0.6111 / f1 score: 0.0\n",
            "epoch: 0 iter: 140032 70% (3m 43s) 0.8857 / f1 score: 0.0\n",
            "epoch: 0 iter: 141056 70% (3m 45s) 0.6181 / f1 score: 0.0\n",
            "epoch: 0 iter: 142080 71% (3m 46s) 0.7949 / f1 score: 0.0\n",
            "epoch: 0 iter: 143104 71% (3m 47s) 0.5325 / f1 score: 0.0\n",
            "epoch: 0 iter: 144128 72% (3m 48s) 0.8837 / f1 score: 0.0\n",
            "epoch: 0 iter: 145024 72% (3m 49s) 0.6185 / f1 score: 0.0\n",
            "epoch: 0 iter: 146048 73% (3m 50s) 0.4411 / f1 score: 0.0\n",
            "epoch: 0 iter: 147072 73% (3m 51s) 0.7961 / f1 score: 0.0\n",
            "epoch: 0 iter: 148096 74% (3m 52s) 0.6172 / f1 score: 0.0\n",
            "epoch: 0 iter: 149120 74% (3m 53s) 0.7959 / f1 score: 0.0\n",
            "epoch: 0 iter: 150016 75% (3m 54s) 1.0591 / f1 score: 0.0\n",
            "--------------------------------------------------evaluating--------------------------------------------------\n",
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 2s)\n",
            "iter: 3072 7% (0m 3s)\n",
            "iter: 4096 9% (0m 4s)\n",
            "iter: 5120 11% (0m 5s)\n",
            "iter: 6016 14% (0m 6s)\n",
            "iter: 7040 16% (0m 7s)\n",
            "iter: 8064 18% (0m 8s)\n",
            "iter: 9088 21% (0m 9s)\n",
            "iter: 10112 23% (0m 10s)\n",
            "iter: 11008 25% (0m 12s)\n",
            "iter: 12032 28% (0m 13s)\n",
            "iter: 13056 30% (0m 14s)\n",
            "iter: 14080 32% (0m 15s)\n",
            "iter: 15104 35% (0m 16s)\n",
            "iter: 16128 37% (0m 18s)\n",
            "iter: 17024 39% (0m 18s)\n",
            "iter: 18048 42% (0m 19s)\n",
            "iter: 19072 44% (0m 21s)\n",
            "iter: 20096 47% (0m 22s)\n",
            "iter: 21120 49% (0m 23s)\n",
            "iter: 22016 51% (0m 24s)\n",
            "iter: 23040 53% (0m 25s)\n",
            "iter: 24064 56% (0m 26s)\n",
            "iter: 25088 58% (0m 27s)\n",
            "iter: 26112 61% (0m 28s)\n",
            "iter: 27008 63% (0m 29s)\n",
            "iter: 28032 65% (0m 30s)\n",
            "iter: 29056 68% (0m 31s)\n",
            "iter: 30080 70% (0m 32s)\n",
            "iter: 31104 72% (0m 33s)\n",
            "iter: 32128 75% (0m 33s)\n",
            "iter: 33024 77% (0m 34s)\n",
            "iter: 34048 79% (0m 35s)\n",
            "iter: 35072 82% (0m 36s)\n",
            "iter: 36096 84% (0m 37s)\n",
            "iter: 37120 86% (0m 38s)\n",
            "iter: 38016 89% (0m 39s)\n",
            "iter: 39040 91% (0m 40s)\n",
            "iter: 40064 93% (0m 41s)\n",
            "iter: 41088 96% (0m 42s)\n",
            "iter: 42112 98% (0m 43s)\n",
            "f1 score: 0.01267605647444725\n",
            "precison score: 0.11999999731779099\n",
            "recall score: 0.006691449787467718\n",
            "epoch: 0 iter: 151040 75% (4m 39s) 0.7935 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 152064 76% (4m 40s) 0.7083 / f1 score: 0.0634920597076416\n",
            "epoch: 0 iter: 153088 76% (4m 41s) 0.5325 / f1 score: 0.03100775182247162\n",
            "epoch: 0 iter: 154112 77% (4m 42s) 0.9687 / f1 score: 0.1093750074505806\n",
            "epoch: 0 iter: 155008 77% (4m 43s) 0.6167 / f1 score: 0.0\n",
            "epoch: 0 iter: 156032 78% (4m 44s) 0.4464 / f1 score: 0.0\n",
            "epoch: 0 iter: 157056 78% (4m 45s) 0.4359 / f1 score: 0.0\n",
            "epoch: 0 iter: 158080 79% (4m 46s) 0.5227 / f1 score: 0.0\n",
            "epoch: 0 iter: 159104 79% (4m 47s) 0.6167 / f1 score: 0.0\n",
            "epoch: 0 iter: 160128 80% (4m 49s) 0.6155 / f1 score: 0.0\n",
            "epoch: 0 iter: 161024 80% (4m 49s) 0.7077 / f1 score: 0.0\n",
            "epoch: 0 iter: 162048 81% (4m 51s) 0.885 / f1 score: 0.0\n",
            "epoch: 0 iter: 163072 81% (4m 52s) 0.7063 / f1 score: 0.0\n",
            "epoch: 0 iter: 164096 82% (4m 53s) 0.6182 / f1 score: 0.0\n",
            "epoch: 0 iter: 165120 82% (4m 54s) 0.7094 / f1 score: 0.0\n",
            "epoch: 0 iter: 166016 83% (4m 55s) 0.7066 / f1 score: 0.0\n",
            "epoch: 0 iter: 167040 83% (4m 56s) 1.06 / f1 score: 0.0\n",
            "epoch: 0 iter: 168064 84% (4m 57s) 0.8826 / f1 score: 0.0\n",
            "epoch: 0 iter: 169088 84% (4m 58s) 1.0695 / f1 score: 0.10447761416435242\n",
            "epoch: 0 iter: 170112 85% (4m 59s) 0.621 / f1 score: 0.04615384712815285\n",
            "epoch: 0 iter: 171008 85% (5m 0s) 0.5937 / f1 score: 0.04580152779817581\n",
            "epoch: 0 iter: 172032 86% (5m 1s) 0.6209 / f1 score: 0.04651162773370743\n",
            "epoch: 0 iter: 173056 86% (5m 2s) 0.793 / f1 score: 0.08000000566244125\n",
            "epoch: 0 iter: 174080 87% (5m 3s) 0.6207 / f1 score: 0.04580152779817581\n",
            "epoch: 0 iter: 175104 87% (5m 4s) 0.7066 / f1 score: 0.0\n",
            "epoch: 0 iter: 176128 88% (5m 5s) 0.8893 / f1 score: 0.0\n",
            "epoch: 0 iter: 177024 88% (5m 6s) 0.721 / f1 score: 0.0\n",
            "epoch: 0 iter: 178048 89% (5m 7s) 0.8883 / f1 score: 0.0\n",
            "epoch: 0 iter: 179072 89% (5m 8s) 0.6187 / f1 score: 0.0\n",
            "epoch: 0 iter: 180096 90% (5m 9s) 0.8829 / f1 score: 0.0\n",
            "epoch: 0 iter: 181120 90% (5m 11s) 0.7939 / f1 score: 0.07692307978868484\n",
            "epoch: 0 iter: 182016 91% (5m 11s) 0.6196 / f1 score: 0.04651162773370743\n",
            "epoch: 0 iter: 183040 91% (5m 13s) 0.449 / f1 score: 0.015625\n",
            "epoch: 0 iter: 184064 92% (5m 14s) 0.7076 / f1 score: 0.06106870248913765\n",
            "epoch: 0 iter: 185088 92% (5m 15s) 0.7081 / f1 score: 0.06060606241226196\n",
            "epoch: 0 iter: 186112 93% (5m 16s) 0.8784 / f1 score: 0.09022556245326996\n",
            "epoch: 0 iter: 187008 93% (5m 17s) 0.621 / f1 score: 0.04615384712815285\n",
            "epoch: 0 iter: 188032 94% (5m 18s) 0.9647 / f1 score: 0.10447761416435242\n",
            "epoch: 0 iter: 189056 94% (5m 19s) 0.6226 / f1 score: 0.046875\n",
            "epoch: 0 iter: 190080 95% (5m 20s) 0.5358 / f1 score: 0.03125\n",
            "epoch: 0 iter: 191104 95% (5m 21s) 0.3658 / f1 score: 0.0\n",
            "epoch: 0 iter: 192128 96% (5m 22s) 0.3617 / f1 score: 0.0\n",
            "epoch: 0 iter: 193024 96% (5m 23s) 0.5331 / f1 score: 0.031496062874794006\n",
            "epoch: 0 iter: 194048 97% (5m 24s) 0.6178 / f1 score: 0.04651162773370743\n",
            "epoch: 0 iter: 195072 97% (5m 25s) 0.7937 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 196096 98% (5m 26s) 0.3628 / f1 score: 0.0\n",
            "epoch: 0 iter: 197120 98% (5m 27s) 0.7921 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 198016 99% (5m 28s) 0.7918 / f1 score: 0.07575757801532745\n",
            "epoch: 0 iter: 199040 99% (5m 29s) 0.791 / f1 score: 0.07575757801532745\n",
            "--------------------------------------------------training--------------------------------------------------\n",
            "epoch: 1 iter: 1024 0% (5m 30s) 0.6184 / f1 score: 0.04800000414252281\n",
            "epoch: 1 iter: 2048 1% (5m 31s) 0.9588 / f1 score: 0.10606060922145844\n",
            "epoch: 1 iter: 3072 1% (5m 33s) 0.6228 / f1 score: 0.04615384712815285\n",
            "epoch: 1 iter: 4096 2% (5m 34s) 0.9576 / f1 score: 0.10769231617450714\n",
            "epoch: 1 iter: 5120 2% (5m 35s) 0.7867 / f1 score: 0.07692307978868484\n",
            "epoch: 1 iter: 6016 3% (5m 36s) 0.4534 / f1 score: 0.01599999889731407\n",
            "epoch: 1 iter: 7040 3% (5m 37s) 0.7015 / f1 score: 0.06451613456010818\n",
            "epoch: 1 iter: 8064 4% (5m 38s) 0.7051 / f1 score: 0.061538465321063995\n",
            "epoch: 1 iter: 9088 4% (5m 39s) 1.3117 / f1 score: 0.15942029654979706\n",
            "epoch: 1 iter: 10112 5% (5m 40s) 0.7057 / f1 score: 0.061538465321063995\n",
            "epoch: 1 iter: 11008 5% (5m 41s) 0.8788 / f1 score: 0.0923076942563057\n",
            "epoch: 1 iter: 12032 6% (5m 42s) 0.7942 / f1 score: 0.07633588463068008\n",
            "epoch: 1 iter: 13056 6% (5m 43s) 0.9665 / f1 score: 0.10526315867900848\n",
            "epoch: 1 iter: 14080 7% (5m 44s) 0.4451 / f1 score: 0.015625\n",
            "epoch: 1 iter: 15104 7% (5m 45s) 0.6161 / f1 score: 0.04838709533214569\n",
            "epoch: 1 iter: 16128 8% (5m 46s) 0.7933 / f1 score: 0.07575757801532745\n",
            "epoch: 1 iter: 17024 8% (5m 47s) 0.5307 / f1 score: 0.03199999779462814\n",
            "epoch: 1 iter: 18048 9% (5m 48s) 0.706 / f1 score: 0.06106870248913765\n",
            "epoch: 1 iter: 19072 9% (5m 49s) 0.6189 / f1 score: 0.04615384712815285\n",
            "epoch: 1 iter: 20096 10% (5m 50s) 0.7061 / f1 score: 0.06451613456010818\n",
            "epoch: 1 iter: 21120 10% (5m 51s) 0.7048 / f1 score: 0.06557376682758331\n",
            "epoch: 1 iter: 22016 11% (5m 52s) 1.0515 / f1 score: 0.0\n",
            "epoch: 1 iter: 23040 11% (5m 53s) 0.5303 / f1 score: 0.03199999779462814\n",
            "epoch: 1 iter: 24064 12% (5m 54s) 0.5314 / f1 score: 0.032258063554763794\n",
            "epoch: 1 iter: 25088 12% (5m 55s) 0.8193 / f1 score: 0.09160305559635162\n",
            "epoch: 1 iter: 26112 13% (5m 56s) 0.7058 / f1 score: 0.06106870248913765\n",
            "epoch: 1 iter: 27008 13% (5m 57s) 0.8777 / f1 score: 0.09022556245326996\n",
            "epoch: 1 iter: 28032 14% (5m 58s) 0.4549 / f1 score: 0.01550387591123581\n",
            "epoch: 1 iter: 29056 14% (5m 59s) 0.5348 / f1 score: 0.0317460298538208\n",
            "epoch: 1 iter: 30080 15% (6m 0s) 0.7901 / f1 score: 0.07575757801532745\n",
            "epoch: 1 iter: 31104 15% (6m 1s) 0.5319 / f1 score: 0.03305785357952118\n",
            "epoch: 1 iter: 32128 16% (6m 3s) 0.6169 / f1 score: 0.04800000414252281\n",
            "epoch: 1 iter: 33024 16% (6m 3s) 0.6221 / f1 score: 0.04580152779817581\n",
            "epoch: 1 iter: 34048 17% (6m 4s) 0.4473 / f1 score: 0.016260161995887756\n",
            "epoch: 1 iter: 35072 17% (6m 6s) 0.7058 / f1 score: 0.062015511095523834\n",
            "epoch: 1 iter: 36096 18% (6m 7s) 0.9669 / f1 score: 0.10447761416435242\n",
            "epoch: 1 iter: 37120 18% (6m 8s) 0.7063 / f1 score: 0.061538465321063995\n",
            "epoch: 1 iter: 38016 19% (6m 9s) 0.9676 / f1 score: 0.10606060922145844\n",
            "epoch: 1 iter: 39040 19% (6m 10s) 0.8813 / f1 score: 0.09022556245326996\n",
            "epoch: 1 iter: 40064 20% (6m 11s) 0.7047 / f1 score: 0.061538465321063995\n",
            "epoch: 1 iter: 41088 20% (6m 12s) 0.5349 / f1 score: 0.03100775182247162\n",
            "epoch: 1 iter: 42112 21% (6m 13s) 0.7061 / f1 score: 0.06106870248913765\n",
            "epoch: 1 iter: 43008 21% (6m 14s) 0.5365 / f1 score: 0.031496062874794006\n",
            "epoch: 1 iter: 44032 22% (6m 15s) 0.7066 / f1 score: 0.062015511095523834\n",
            "epoch: 1 iter: 45056 22% (6m 16s) 0.8793 / f1 score: 0.09022556245326996\n",
            "epoch: 1 iter: 46080 23% (6m 17s) 0.6199 / f1 score: 0.04878048971295357\n",
            "epoch: 1 iter: 47104 23% (6m 18s) 0.8754 / f1 score: 0.09090908616781235\n",
            "epoch: 1 iter: 48128 24% (6m 19s) 0.6141 / f1 score: 0.04878048971295357\n",
            "epoch: 1 iter: 49024 24% (6m 20s) 0.4512 / f1 score: 0.01587301678955555\n",
            "epoch: 1 iter: 50048 25% (6m 21s) 0.6204 / f1 score: 0.04651162773370743\n",
            "--------------------------------------------------evaluating--------------------------------------------------\n",
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 1s)\n",
            "iter: 3072 7% (0m 2s)\n",
            "iter: 4096 9% (0m 3s)\n",
            "iter: 5120 11% (0m 4s)\n",
            "iter: 6016 14% (0m 5s)\n",
            "iter: 7040 16% (0m 6s)\n",
            "iter: 8064 18% (0m 7s)\n",
            "iter: 9088 21% (0m 8s)\n",
            "iter: 10112 23% (0m 9s)\n",
            "iter: 11008 25% (0m 10s)\n",
            "iter: 12032 28% (0m 11s)\n",
            "iter: 13056 30% (0m 11s)\n",
            "iter: 14080 32% (0m 12s)\n",
            "iter: 15104 35% (0m 13s)\n",
            "iter: 16128 37% (0m 14s)\n",
            "iter: 17024 39% (0m 15s)\n",
            "iter: 18048 42% (0m 16s)\n",
            "iter: 19072 44% (0m 17s)\n",
            "iter: 20096 47% (0m 18s)\n",
            "iter: 21120 49% (0m 19s)\n",
            "iter: 22016 51% (0m 20s)\n",
            "iter: 23040 53% (0m 21s)\n",
            "iter: 24064 56% (0m 21s)\n",
            "iter: 25088 58% (0m 22s)\n",
            "iter: 26112 61% (0m 23s)\n",
            "iter: 27008 63% (0m 24s)\n",
            "iter: 28032 65% (0m 25s)\n",
            "iter: 29056 68% (0m 26s)\n",
            "iter: 30080 70% (0m 27s)\n",
            "iter: 31104 72% (0m 28s)\n",
            "iter: 32128 75% (0m 29s)\n",
            "iter: 33024 77% (0m 30s)\n",
            "iter: 34048 79% (0m 31s)\n",
            "iter: 35072 82% (0m 32s)\n",
            "iter: 36096 84% (0m 33s)\n",
            "iter: 37120 86% (0m 34s)\n",
            "iter: 38016 89% (0m 35s)\n",
            "iter: 39040 91% (0m 35s)\n",
            "iter: 40064 93% (0m 36s)\n",
            "iter: 41088 96% (0m 37s)\n",
            "iter: 42112 98% (0m 38s)\n",
            "f1 score: 0.06211771443486214\n",
            "precison score: 0.032085955142974854\n",
            "recall score: 0.9702602028846741\n",
            "epoch: 1 iter: 51072 25% (7m 1s) 0.5242 / f1 score: 0.0357142835855484\n",
            "epoch: 1 iter: 52096 26% (7m 2s) 0.7046 / f1 score: 0.0555555559694767\n",
            "epoch: 1 iter: 53120 26% (7m 4s) 0.7789 / f1 score: 0.09345794469118118\n",
            "epoch: 1 iter: 54016 27% (7m 4s) 0.4443 / f1 score: 0.01599999889731407\n",
            "epoch: 1 iter: 55040 27% (7m 6s) 0.6159 / f1 score: 0.049180325120687485\n",
            "epoch: 1 iter: 56064 28% (7m 7s) 1.2348 / f1 score: 0.0\n",
            "epoch: 1 iter: 57088 28% (7m 8s) 0.7927 / f1 score: 0.07575757801532745\n",
            "epoch: 1 iter: 58112 29% (7m 9s) 1.0578 / f1 score: 0.131386861205101\n",
            "epoch: 1 iter: 59008 29% (7m 10s) 0.4574 / f1 score: 0.015748033300042152\n",
            "epoch: 1 iter: 60032 30% (7m 11s) 0.4581 / f1 score: 0.015748033300042152\n",
            "epoch: 1 iter: 61056 30% (7m 12s) 0.6496 / f1 score: 0.07407407462596893\n",
            "epoch: 1 iter: 62080 31% (7m 13s) 0.6188 / f1 score: 0.04651162773370743\n",
            "epoch: 1 iter: 63104 31% (7m 14s) 0.5278 / f1 score: 0.03669724985957146\n",
            "epoch: 1 iter: 64128 32% (7m 15s) 0.8794 / f1 score: 0.0\n",
            "epoch: 1 iter: 65024 32% (7m 16s) 0.4265 / f1 score: 0.0\n",
            "epoch: 1 iter: 66048 33% (7m 17s) 0.653 / f1 score: 0.3333333432674408\n",
            "epoch: 1 iter: 67072 33% (7m 18s) 0.5245 / f1 score: 0.0\n",
            "epoch: 1 iter: 68096 34% (7m 19s) 0.8346 / f1 score: 0.0\n",
            "epoch: 1 iter: 69120 34% (7m 20s) 0.3686 / f1 score: 0.25\n",
            "epoch: 1 iter: 70016 35% (7m 21s) 0.9461 / f1 score: 0.222222238779068\n",
            "epoch: 1 iter: 71040 35% (7m 22s) 0.4237 / f1 score: 0.0\n",
            "epoch: 1 iter: 72064 36% (7m 23s) 0.6855 / f1 score: 0.0\n",
            "epoch: 1 iter: 73088 36% (7m 24s) 0.5966 / f1 score: 0.0\n",
            "epoch: 1 iter: 74112 37% (7m 25s) 0.515 / f1 score: 0.0\n",
            "epoch: 1 iter: 75008 37% (7m 26s) 0.648 / f1 score: 0.3333333432674408\n",
            "epoch: 1 iter: 76032 38% (7m 27s) 0.6108 / f1 score: 0.0\n",
            "epoch: 1 iter: 77056 38% (7m 28s) 0.8249 / f1 score: 0.0\n",
            "epoch: 1 iter: 78080 39% (7m 29s) 0.8027 / f1 score: 0.0\n",
            "epoch: 1 iter: 79104 39% (7m 30s) 0.5253 / f1 score: 0.0\n",
            "epoch: 1 iter: 80128 40% (7m 31s) 0.7961 / f1 score: 0.0\n",
            "epoch: 1 iter: 81024 40% (7m 32s) 0.5209 / f1 score: 0.0\n",
            "epoch: 1 iter: 82048 41% (7m 33s) 0.7003 / f1 score: 0.0\n",
            "epoch: 1 iter: 83072 41% (7m 34s) 0.7455 / f1 score: 0.3333333134651184\n",
            "epoch: 1 iter: 84096 42% (7m 35s) 0.4354 / f1 score: 0.0\n",
            "epoch: 1 iter: 85120 42% (7m 37s) 0.7065 / f1 score: 0.0\n",
            "epoch: 1 iter: 86016 43% (7m 37s) 0.5263 / f1 score: 0.0\n",
            "epoch: 1 iter: 87040 43% (7m 39s) 0.808 / f1 score: 0.0\n",
            "epoch: 1 iter: 88064 44% (7m 40s) 0.6168 / f1 score: 0.0\n",
            "epoch: 1 iter: 89088 44% (7m 41s) 0.8155 / f1 score: 0.25\n",
            "epoch: 1 iter: 90112 45% (7m 42s) 0.3489 / f1 score: 0.0\n",
            "epoch: 1 iter: 91008 45% (7m 43s) 0.5486 / f1 score: 0.4000000059604645\n",
            "epoch: 1 iter: 92032 46% (7m 44s) 0.4317 / f1 score: 0.0\n",
            "epoch: 1 iter: 93056 46% (7m 45s) 0.3318 / f1 score: 0.0\n",
            "epoch: 1 iter: 94080 47% (7m 46s) 0.703 / f1 score: 0.0\n",
            "epoch: 1 iter: 95104 47% (7m 47s) 0.6498 / f1 score: 0.0\n",
            "epoch: 1 iter: 96128 48% (7m 48s) 0.4333 / f1 score: 0.6666666865348816\n",
            "epoch: 1 iter: 97024 48% (7m 49s) 0.6338 / f1 score: 0.0\n",
            "epoch: 1 iter: 98048 49% (7m 50s) 0.5268 / f1 score: 0.0\n",
            "epoch: 1 iter: 99072 49% (7m 51s) 0.6123 / f1 score: 0.0\n",
            "epoch: 1 iter: 100096 50% (7m 52s) 0.8146 / f1 score: 0.0\n",
            "--------------------------------------------------evaluating--------------------------------------------------\n",
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 1s)\n",
            "iter: 3072 7% (0m 2s)\n",
            "iter: 4096 9% (0m 3s)\n",
            "iter: 5120 11% (0m 4s)\n",
            "iter: 6016 14% (0m 5s)\n",
            "iter: 7040 16% (0m 6s)\n",
            "iter: 8064 18% (0m 7s)\n",
            "iter: 9088 21% (0m 8s)\n",
            "iter: 10112 23% (0m 9s)\n",
            "iter: 11008 25% (0m 10s)\n",
            "iter: 12032 28% (0m 11s)\n",
            "iter: 13056 30% (0m 11s)\n",
            "iter: 14080 32% (0m 12s)\n",
            "iter: 15104 35% (0m 13s)\n",
            "iter: 16128 37% (0m 14s)\n",
            "iter: 17024 39% (0m 15s)\n",
            "iter: 18048 42% (0m 16s)\n",
            "iter: 19072 44% (0m 17s)\n",
            "iter: 20096 47% (0m 18s)\n",
            "iter: 21120 49% (0m 19s)\n",
            "iter: 22016 51% (0m 20s)\n",
            "iter: 23040 53% (0m 20s)\n",
            "iter: 24064 56% (0m 21s)\n",
            "iter: 25088 58% (0m 22s)\n",
            "iter: 26112 61% (0m 23s)\n",
            "iter: 27008 63% (0m 24s)\n",
            "iter: 28032 65% (0m 25s)\n",
            "iter: 29056 68% (0m 26s)\n",
            "iter: 30080 70% (0m 27s)\n",
            "iter: 31104 72% (0m 28s)\n",
            "iter: 32128 75% (0m 29s)\n",
            "iter: 33024 77% (0m 29s)\n",
            "iter: 34048 79% (0m 30s)\n",
            "iter: 35072 82% (0m 31s)\n",
            "iter: 36096 84% (0m 32s)\n",
            "iter: 37120 86% (0m 33s)\n",
            "iter: 38016 89% (0m 34s)\n",
            "iter: 39040 91% (0m 35s)\n",
            "iter: 40064 93% (0m 36s)\n",
            "iter: 41088 96% (0m 37s)\n",
            "iter: 42112 98% (0m 38s)\n",
            "f1 score: 0.08752734959125519\n",
            "precison score: 0.1656314730644226\n",
            "recall score: 0.05947955325245857\n",
            "epoch: 1 iter: 101120 50% (8m 32s) 0.7004 / f1 score: 0.0\n",
            "epoch: 1 iter: 102016 51% (8m 33s) 0.6023 / f1 score: 0.0\n",
            "epoch: 1 iter: 103040 51% (8m 34s) 0.5105 / f1 score: 0.0\n",
            "epoch: 1 iter: 104064 52% (8m 35s) 0.7795 / f1 score: 0.0\n",
            "epoch: 1 iter: 105088 52% (8m 36s) 0.7019 / f1 score: 0.25\n",
            "epoch: 1 iter: 106112 53% (8m 37s) 0.5639 / f1 score: 0.06976743787527084\n",
            "epoch: 1 iter: 107008 53% (8m 38s) 0.795 / f1 score: 0.051948051899671555\n",
            "epoch: 1 iter: 108032 54% (8m 39s) 0.8625 / f1 score: 0.08849557489156723\n",
            "epoch: 1 iter: 109056 54% (8m 40s) 0.703 / f1 score: 0.06557376682758331\n",
            "epoch: 1 iter: 110080 55% (8m 41s) 0.4292 / f1 score: 0.020202020183205605\n",
            "epoch: 1 iter: 111104 55% (8m 42s) 0.5283 / f1 score: 0.0\n",
            "epoch: 1 iter: 112128 56% (8m 43s) 0.7071 / f1 score: 0.0\n",
            "epoch: 1 iter: 113024 56% (8m 44s) 0.3976 / f1 score: 0.6666666865348816\n",
            "epoch: 1 iter: 114048 57% (8m 45s) 0.6246 / f1 score: 0.4000000059604645\n",
            "epoch: 1 iter: 115072 57% (8m 46s) 0.807 / f1 score: 0.25\n",
            "epoch: 1 iter: 116096 58% (8m 47s) 0.7045 / f1 score: 0.0\n",
            "epoch: 1 iter: 117120 58% (8m 48s) 0.5404 / f1 score: 0.0\n",
            "epoch: 1 iter: 118016 59% (8m 49s) 0.8958 / f1 score: 0.25\n",
            "epoch: 1 iter: 119040 59% (8m 50s) 0.7973 / f1 score: 0.0\n",
            "epoch: 1 iter: 120064 60% (8m 52s) 0.4978 / f1 score: 0.0\n",
            "epoch: 1 iter: 121088 60% (8m 53s) 0.7799 / f1 score: 0.0\n",
            "epoch: 1 iter: 122112 61% (8m 54s) 0.3502 / f1 score: 0.0\n",
            "epoch: 1 iter: 123008 61% (8m 55s) 0.697 / f1 score: 0.10810811072587967\n",
            "epoch: 1 iter: 124032 62% (8m 56s) 0.5781 / f1 score: 0.0\n",
            "epoch: 1 iter: 125056 62% (8m 57s) 0.8014 / f1 score: 0.0\n",
            "epoch: 1 iter: 126080 63% (8m 58s) 0.8832 / f1 score: 0.08955223858356476\n",
            "epoch: 1 iter: 127104 63% (8m 59s) 0.9602 / f1 score: 0.11864407360553741\n",
            "epoch: 1 iter: 128128 64% (9m 0s) 0.4455 / f1 score: 0.01666666567325592\n",
            "epoch: 1 iter: 129024 64% (9m 1s) 0.8544 / f1 score: 0.06451613456010818\n",
            "epoch: 1 iter: 130048 65% (9m 2s) 0.5254 / f1 score: 0.0317460298538208\n",
            "epoch: 1 iter: 131072 65% (9m 3s) 0.4756 / f1 score: 0.039603959769010544\n",
            "epoch: 1 iter: 132096 66% (9m 4s) 0.5216 / f1 score: 0.03809523582458496\n",
            "epoch: 1 iter: 133120 66% (9m 5s) 0.6082 / f1 score: 0.05263157933950424\n",
            "epoch: 1 iter: 134016 67% (9m 6s) 0.6827 / f1 score: 0.023529410362243652\n",
            "epoch: 1 iter: 135040 67% (9m 7s) 0.784 / f1 score: 0.08620689809322357\n",
            "epoch: 1 iter: 136064 68% (9m 8s) 0.7733 / f1 score: 0.0\n",
            "epoch: 1 iter: 137088 68% (9m 9s) 0.7095 / f1 score: 0.0\n",
            "epoch: 1 iter: 138112 69% (9m 10s) 0.9578 / f1 score: 0.04938271641731262\n",
            "epoch: 1 iter: 139008 69% (9m 11s) 0.7477 / f1 score: 0.08264462649822235\n",
            "epoch: 1 iter: 140032 70% (9m 12s) 0.7575 / f1 score: 0.07633588463068008\n",
            "epoch: 1 iter: 141056 70% (9m 13s) 0.6714 / f1 score: 0.0727272778749466\n",
            "epoch: 1 iter: 142080 71% (9m 14s) 0.6165 / f1 score: 0.04999999701976776\n",
            "epoch: 1 iter: 143104 71% (9m 16s) 0.6929 / f1 score: 0.06722688674926758\n",
            "epoch: 1 iter: 144128 72% (9m 17s) 0.6691 / f1 score: 0.08264462649822235\n",
            "epoch: 1 iter: 145024 72% (9m 17s) 0.7877 / f1 score: 0.06315789371728897\n",
            "epoch: 1 iter: 146048 73% (9m 19s) 0.8777 / f1 score: 0.08196721225976944\n",
            "epoch: 1 iter: 147072 73% (9m 20s) 0.6058 / f1 score: 0.052173912525177\n",
            "epoch: 1 iter: 148096 74% (9m 21s) 0.5333 / f1 score: 0.0317460298538208\n",
            "epoch: 1 iter: 149120 74% (9m 22s) 1.0445 / f1 score: 0.12030075490474701\n",
            "epoch: 1 iter: 150016 75% (9m 23s) 0.659 / f1 score: 0.08421052992343903\n",
            "--------------------------------------------------evaluating--------------------------------------------------\n",
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 2% (0m 1s)\n",
            "iter: 2048 4% (0m 1s)\n",
            "iter: 3072 7% (0m 2s)\n",
            "iter: 4096 9% (0m 3s)\n",
            "iter: 5120 11% (0m 4s)\n",
            "iter: 6016 14% (0m 5s)\n",
            "iter: 7040 16% (0m 6s)\n",
            "iter: 8064 18% (0m 7s)\n",
            "iter: 9088 21% (0m 8s)\n",
            "iter: 10112 23% (0m 9s)\n",
            "iter: 11008 25% (0m 10s)\n",
            "iter: 12032 28% (0m 11s)\n",
            "iter: 13056 30% (0m 11s)\n",
            "iter: 14080 32% (0m 12s)\n",
            "iter: 15104 35% (0m 13s)\n",
            "iter: 16128 37% (0m 14s)\n",
            "iter: 17024 39% (0m 15s)\n",
            "iter: 18048 42% (0m 16s)\n",
            "iter: 19072 44% (0m 17s)\n",
            "iter: 20096 47% (0m 18s)\n",
            "iter: 21120 49% (0m 19s)\n",
            "iter: 22016 51% (0m 20s)\n",
            "iter: 23040 53% (0m 20s)\n",
            "iter: 24064 56% (0m 21s)\n",
            "iter: 25088 58% (0m 22s)\n",
            "iter: 26112 61% (0m 23s)\n",
            "iter: 27008 63% (0m 24s)\n",
            "iter: 28032 65% (0m 25s)\n",
            "iter: 29056 68% (0m 26s)\n",
            "iter: 30080 70% (0m 27s)\n",
            "iter: 31104 72% (0m 28s)\n",
            "iter: 32128 75% (0m 29s)\n",
            "iter: 33024 77% (0m 29s)\n",
            "iter: 34048 79% (0m 30s)\n",
            "iter: 35072 82% (0m 31s)\n",
            "iter: 36096 84% (0m 32s)\n",
            "iter: 37120 86% (0m 33s)\n",
            "iter: 38016 89% (0m 34s)\n",
            "iter: 39040 91% (0m 35s)\n",
            "iter: 40064 93% (0m 36s)\n",
            "iter: 41088 96% (0m 37s)\n",
            "iter: 42112 98% (0m 38s)\n",
            "f1 score: 0.06964869052171707\n",
            "precison score: 0.036182302981615067\n",
            "recall score: 0.9278810620307922\n",
            "epoch: 1 iter: 151040 75% (10m 2s) 0.5167 / f1 score: 0.03478260710835457\n",
            "epoch: 1 iter: 152064 76% (10m 3s) 1.0381 / f1 score: 0.12844036519527435\n",
            "epoch: 1 iter: 153088 76% (10m 4s) 1.041 / f1 score: 0.12121212482452393\n",
            "epoch: 1 iter: 154112 77% (10m 6s) 0.3958 / f1 score: 0.02247191034257412\n",
            "epoch: 1 iter: 155008 77% (10m 6s) 1.0208 / f1 score: 0.10256409645080566\n",
            "epoch: 1 iter: 156032 78% (10m 7s) 0.788 / f1 score: 0.10526315867900848\n",
            "epoch: 1 iter: 157056 78% (10m 9s) 0.6788 / f1 score: 0.07619047909975052\n",
            "epoch: 1 iter: 158080 79% (10m 10s) 0.8664 / f1 score: 0.09999999403953552\n",
            "epoch: 1 iter: 159104 79% (10m 11s) 0.6785 / f1 score: 0.0747663602232933\n",
            "epoch: 1 iter: 160128 80% (10m 12s) 0.5351 / f1 score: 0.0317460298538208\n",
            "epoch: 1 iter: 161024 80% (10m 13s) 0.9494 / f1 score: 0.11965812742710114\n",
            "epoch: 1 iter: 162048 81% (10m 14s) 0.6957 / f1 score: 0.08547009527683258\n",
            "epoch: 1 iter: 163072 81% (10m 15s) 0.7817 / f1 score: 0.1599999964237213\n",
            "epoch: 1 iter: 164096 82% (10m 16s) 0.5209 / f1 score: 0.09677419811487198\n",
            "epoch: 1 iter: 165120 82% (10m 17s) 0.7206 / f1 score: 0.10752688348293304\n",
            "epoch: 1 iter: 166016 83% (10m 18s) 0.7491 / f1 score: 0.09708738327026367\n"
          ]
        }
      ],
      "source": [
        "f1 = F1Score(num_classes=1).cuda()\n",
        "start = time.time()\n",
        "for epoch in range(max_epochs):\n",
        "    # Training\n",
        "    print_count = 1\n",
        "    plot_count = 1\n",
        "    for iter, (local_batch, local_labels) in enumerate(train_loader):\n",
        "        # Model computations\n",
        "        preds, loss = train(local_batch, local_labels)\n",
        "        current_loss += loss\n",
        "        if iter * batch_size > print_every * print_count:\n",
        "          labels = torch.tensor(local_labels).cuda()\n",
        "          correct = f'f1 score: {f1(preds[0], labels)}' \n",
        "          print(f'epoch: {epoch} iter: {iter* batch_size} {math.floor(iter* batch_size/len(train_dataset) * 100)}% ({timeSince(start)}) {round(loss, 4)} / {correct}')\n",
        "          print_count += 1\n",
        "        if iter * batch_size > plot_every * plot_count:\n",
        "          eval_loss, f1_score, precision_score, recall_score = evaluate(model)\n",
        "          all_eval_losses.append(eval_loss)\n",
        "          all_lstm_losses.append(current_loss/ plot_every)\n",
        "          current_loss = 0\n",
        "          plot_count += 1\n",
        "    print(50*'-' + 'training' + 50*'-')\n",
        "torch.save(model.state_dict(), f'/content/drive/MyDrive/models/model_{model_name}_{mode}.pth')\n",
        "    "
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "evaluate(model, is_test=True)"
      ],
      "metadata": {
        "id": "TMoLi4RCEH6N",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1314bea1-9dcb-49bc-fd01-81cd6916217c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--------------------------------------------------evaluating--------------------------------------------------\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:61: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:22: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "iter: 128 0% (0m 0s)\n",
            "iter: 1024 3% (0m 1s)\n",
            "iter: 2048 7% (0m 2s)\n",
            "iter: 3072 11% (0m 2s)\n",
            "iter: 4096 14% (0m 3s)\n",
            "iter: 5120 18% (0m 4s)\n",
            "iter: 6016 21% (0m 5s)\n",
            "iter: 7040 25% (0m 6s)\n",
            "iter: 8064 29% (0m 7s)\n",
            "iter: 9088 33% (0m 8s)\n",
            "iter: 10112 36% (0m 10s)\n",
            "iter: 11008 40% (0m 12s)\n",
            "iter: 12032 43% (0m 13s)\n",
            "iter: 13056 47% (0m 14s)\n",
            "iter: 14080 51% (0m 14s)\n",
            "iter: 15104 55% (0m 15s)\n",
            "iter: 16128 58% (0m 16s)\n",
            "iter: 17024 62% (0m 17s)\n",
            "iter: 18048 65% (0m 18s)\n",
            "iter: 19072 69% (0m 19s)\n",
            "iter: 20096 73% (0m 20s)\n",
            "iter: 21120 76% (0m 21s)\n",
            "iter: 22016 80% (0m 22s)\n",
            "iter: 23040 83% (0m 23s)\n",
            "iter: 24064 87% (0m 24s)\n",
            "iter: 25088 91% (0m 25s)\n",
            "iter: 26112 95% (0m 25s)\n",
            "iter: 27008 98% (0m 26s)\n",
            "f1 score: 0.8919824957847595\n",
            "precison score: 0.8116350173950195\n",
            "recall score: 0.9899857044219971\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:37: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
            "/usr/local/lib/python3.7/dist-packages/ipykernel_launcher.py:38: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(tensor(0.0640),\n",
              " tensor(0.8920, device='cuda:0'),\n",
              " tensor(0.8116, device='cuda:0'),\n",
              " tensor(0.9900, device='cuda:0'))"
            ]
          },
          "metadata": {},
          "execution_count": 194
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "lstm_losses = []"
      ],
      "metadata": {
        "id": "8bmpj6H2qKmm"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyPPG+PRSoJWQqGfoIdF8eYS",
      "include_colab_link": true
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}